{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Following code in notebook is solely to demonstrate the usage of pre-trained models from HuggingFace and deploy in Azure by leveraging the services\n",
        "\n",
        "\n",
        "\n",
        "### Deploy question-answering models from HuggingFaceHub to AzureML Online Endpoints\n",
        "\n",
        "This sample shows how to deploy `deepset-roberta-base-squad2` `question-answering` models from the HuggingFaceHub to an online endpoint for inference. Learn more about `question-answering` task: https://huggingface.co/tasks/question-answering\n",
        "\n",
        "A large set of models hosted on [Hugging Face Hub](https://huggingface.co/models) are available in the Hugging Face Hub collection in AzureML Model Catalog. This collection is powered by the Hugging Face Hub community registry. Integration with the AzureML Model Catalog enables seamless deployment of Hugging Face Hub models in AzureML. _todo: learn more link_\n",
        "\n",
        "### Outline\n",
        "* Set up pre-requisites.\n",
        "* Pick a model to deploy.\n",
        "* Deploy the model for real time inference.\n",
        "* Try sample inference.\n",
        "* Clean up resources."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Set up pre-requisites\n",
        "* Install dependencies\n",
        "* Connect to AzureML Workspace. Learn more at [set up SDK authentication](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk). Replace  `<WORKSPACE_NAME>`, `<RESOURCE_GROUP>` and `<SUBSCRIPTION_ID>` below.\n",
        "* Connect to `HuggingFaceHub` community registry"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import (\n",
        "    DefaultAzureCredential,\n",
        "    InteractiveBrowserCredential,\n",
        "    ClientSecretCredential,\n",
        ")\n",
        "from azure.ai.ml.entities import AmlCompute\n",
        "import time\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "# connect to a workspace\n",
        "workspace_ml_client = None\n",
        "try:\n",
        "    workspace_ml_client = MLClient.from_config(credential)\n",
        "    subscription_id = workspace_ml_client.subscription_id\n",
        "    workspace = workspace_ml_client.workspace_name\n",
        "    resource_group = workspace_ml_client.resource_group_name\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    \n",
        "    # Enter details of your workspace\n",
        "    # subscription_id=\"<SUBSCRIPTION_ID>\",\n",
        "    # resource_group =\"<RESOURCE_GROUP>\",\n",
        "    # workspace = \"<WORKSPACE_NAME>\",\n",
        "    \n",
        "    workspace_ml_client = MLClient(\n",
        "        credential, subscription_id, resource_group, workspace\n",
        "    )\n",
        "# Connect to the HuggingFaceHub registry\n",
        "registry_ml_client = MLClient(credential, registry_name=\"HuggingFace\")\n",
        "print(registry_ml_client)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7faf643b45e0>,\n         subscription_id=d5210851-d1ca-44ac-8071-a0c7191e9631,\n         resource_group_name=prod-azure-ml-registry,\n         workspace_name=None)\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1703413181543
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Pick a model to deploy\n",
        "\n",
        "Check if the model `deepset-roberta-base-squad2` exists in Azure model registry"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"deepset-roberta-base-squad2\"\n",
        "foundation_model = registry_ml_client.models.get(model_name, version=\"17\")\n",
        "print(\n",
        "    \"\\n\\nUsing model name: {0}, version: {1}, id: {2} for inferencing\".format(\n",
        "        foundation_model.name, foundation_model.version, foundation_model.id\n",
        "    )\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\nUsing model name: deepset-roberta-base-squad2, version: 17, id: azureml://registries/HuggingFace/models/deepset-roberta-base-squad2/versions/17 for inferencing\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1703413187773
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Deploy the model to an online endpoint\n",
        "Online endpoints give a durable REST API that can be used to integrate with applications that need to use the model. Create an online endpoint and then create an online deployment. You need to specify the Virtual Machine instance or SKU when creating the deployment. You can find the optimal CPU or GPU SKU for a model by opening the quick deployment dialog from the model page in the AzureML Model Catalog. Specify the SKU in the `instance_type` input in deployment settings below.\n",
        "\n",
        "Typically Online Endpoints require you to provide scoring script and a docker container image (through an AzureML environment), in addition to the model. You don't need to worry about them for HuggingFace Hub models available in AzureML Model Catalog because we have enabled 'no code deployments' for these models by packaging scoring script and container image along with the model.\n",
        "\n",
        "Learn more about Online Endpoints: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-online-endpoints"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import time, sys\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    OnlineRequestSettings,\n",
        ")\n",
        "\n",
        "# Create online endpoint - endpoint names need to be unique in a region, hence using timestamp to create unique endpoint name\n",
        "timestamp = int(time.time())\n",
        "online_endpoint_name = \"question-answering-\" + 'OpsChatBot'\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"Online endpoint for \"\n",
        "    + foundation_model.name\n",
        "    + \", for question-answering task\",\n",
        "    auth_mode=\"key\",\n",
        ")\n",
        "workspace_ml_client.begin_create_or_update(endpoint).wait()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1703407732952
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "demo_deployment = ManagedOnlineDeployment(\n",
        "    name=\"demo\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=foundation_model.id,\n",
        "    instance_type=\"Standard_DS3_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "workspace_ml_client.online_deployments.begin_create_or_update(demo_deployment).wait()\n",
        "\n",
        "# online endpoints can have multiple deployments with traffic split or shadow traffic. Set traffic to 100% for demo deployment\n",
        "endpoint.traffic = {\"demo\": 100}\n",
        "workspace_ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint question-answering-OpsChatBot exists\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "......................................................................................................................."
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://question-answering-opschatbot.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://question-answering-opschatbot.eastus2.inference.ml.azure.com/swagger.json', 'name': 'question-answering-opschatbot', 'description': 'Online endpoint for deepset-roberta-base-squad2, for question-answering task', 'tags': {'DeploymentId': '1178393', 'LaunchId': '37178', 'LaunchType': 'ON_DEMAND_LAB', 'TemplateId': '7490', 'TenantId': '277'}, 'properties': {'azureml.onlineendpointid': '/subscriptions/aea5d50a-8c8c-4b2f-ac7f-dea01e3b15f2/resourcegroups/talent-acquisition-1178393/providers/microsoft.machinelearningservices/workspaces/gowtham-ml/onlineendpoints/question-answering-opschatbot', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/aea5d50a-8c8c-4b2f-ac7f-dea01e3b15f2/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oe:d895dc86-ba1c-4e0f-aab0-418e360da7b8:8b7d92d5-913d-4d68-a150-16058b267c05?api-version=2022-02-01-preview'}, 'print_as_yaml': True, 'id': '/subscriptions/aea5d50a-8c8c-4b2f-ac7f-dea01e3b15f2/resourceGroups/talent-acquisition-1178393/providers/Microsoft.MachineLearningServices/workspaces/gowtham-ml/onlineEndpoints/question-answering-opschatbot', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/wellsfargouser021/code/Users/WellsfargoUser02', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fc794cf00a0>, 'auth_mode': 'key', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7fc794cf01c0>, 'traffic': {'demo': 100}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1703408382850
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Try sample inference\n",
        "\n",
        "Online endpoints expose a REST API that can be integrated into your applications. Learn how to fetch the scoring REST API and credentials for online endpoints here: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-authenticate-online-endpoint\n",
        "\n",
        "In this example, we will use the Python SDK helper method to invoke the endpoint. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the model object from HuggingFaceHub. We can use it to check for sample test data\n",
        "import urllib.request, json\n",
        "\n",
        "raw_data = urllib.request.urlopen(\n",
        "    \"https://huggingface.co/api/models/\" + foundation_model.tags[\"modelId\"]\n",
        ")\n",
        "\n",
        "print(\"https://huggingface.co/api/models/\" + foundation_model.tags[\"modelId\"])\n",
        "data = json.load(raw_data)\n",
        "\n",
        "print('modelId ', data['modelId'], ',Author', data['author'], ',Last Modified', data['lastModified'])\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://huggingface.co/api/models/deepset/roberta-base-squad2\nmodelId  deepset/roberta-base-squad2 ,Author deepset ,Last Modified 2023-09-26T11:36:30.000Z\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1703413564832
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the sample dataset from HuggingFace for model `deepset/roberta-base-squad2`"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(data[\"widgetData\"], indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[\n  {\n    \"text\": \"Where do I live?\",\n    \"context\": \"My name is Wolfgang and I live in Berlin\"\n  },\n  {\n    \"text\": \"Where do I live?\",\n    \"context\": \"My name is Sarah and I live in London\"\n  },\n  {\n    \"text\": \"What's my name?\",\n    \"context\": \"My name is Clara and I live in Berkeley.\"\n  },\n  {\n    \"text\": \"Which name is also used to describe the Amazon rainforest in English?\",\n    \"context\": \"The Amazon rainforest (Portuguese: Floresta Amaz\\u00f4nica or Amaz\\u00f4nia; Spanish: Selva Amaz\\u00f3nica, Amazon\\u00eda or usually Amazonia; French: For\\u00eat amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \\\"Amazonas\\\" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.\"\n  }\n]\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1703413474641
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if there is sample inference data available on HuggingFaceHub for the model, else try with the backup sample data\n",
        "scoring_file = \"./sample_score.json\"\n",
        "inputs = {}\n",
        "input_question = []\n",
        "input_context = []\n",
        "if \"widgetData\" in data:\n",
        "    for input in data[\"widgetData\"]:\n",
        "        input_question.append(input[\"text\"])\n",
        "        input_context.append(input[\"context\"])\n",
        "    inputs[\"question\"] = input_question\n",
        "    inputs[\"context\"] = input_context\n",
        "    # write the sample_score.json file\n",
        "    score_dict = {\"inputs\": inputs}\n",
        "    with open(scoring_file, \"w\") as outfile:\n",
        "        json.dump(score_dict, outfile, indent=2)\n",
        "else:\n",
        "    scoring_file = \"./sample_score_backup.json\"\n",
        "\n",
        "# print the sample scoring file\n",
        "print(\"\\n\\nSample scoring file: \")\n",
        "with open(scoring_file) as json_file:\n",
        "    scoring_data = json.load(json_file)\n",
        "    print(scoring_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\nSample scoring file: \n{'inputs': {'question': ['Where do I live?', 'Where do I live?', \"What's my name?\", 'Which name is also used to describe the Amazon rainforest in English?'], 'context': ['My name is Wolfgang and I live in Berlin', 'My name is Sarah and I live in London', 'My name is Clara and I live in Berkeley.', 'The Amazon rainforest (Portuguese: Floresta Amazônica or Amazônia; Spanish: Selva Amazónica, Amazonía or usually Amazonia; French: Forêt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \"Amazonas\" in their names. The Amazon represents over half of the planet\\'s remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.']}}\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1703408383754
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# score the sample_score.json file using the online endpoint with the azureml endpoint invoke method\n",
        "\n",
        "response = workspace_ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    deployment_name=\"demo\",\n",
        "    request_file=scoring_file,\n",
        ")\n",
        "response_json = json.loads(response)\n",
        "print(json.dumps(response_json, indent=2))\n",
        "\n",
        "# workspace_ml_client.online_deployments.get(demo_deployment)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[\n  {\n    \"score\": 0.9190715551376343,\n    \"start\": 34,\n    \"end\": 40,\n    \"answer\": \"Berlin\"\n  },\n  {\n    \"score\": 0.7772308588027954,\n    \"start\": 31,\n    \"end\": 37,\n    \"answer\": \"London\"\n  },\n  {\n    \"score\": 0.9326565265655518,\n    \"start\": 11,\n    \"end\": 16,\n    \"answer\": \"Clara\"\n  },\n  {\n    \"score\": 0.750623881816864,\n    \"start\": 201,\n    \"end\": 230,\n    \"answer\": \"Amazonia or the Amazon Jungle\"\n  }\n]\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1703408384096
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# score the sample_score.json file using the online endpoint with the azureml endpoint invoke method\n",
        "\n",
        "response = workspace_ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    deployment_name=\"demo\",\n",
        "    request_file=scoring_file,\n",
        ")\n",
        "response_json = json.loads(response)\n",
        "print(json.dumps(response_json, indent=2))\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[\n  {\n    \"score\": 0.9190715551376343,\n    \"start\": 34,\n    \"end\": 40,\n    \"answer\": \"Berlin\"\n  },\n  {\n    \"score\": 0.7772308588027954,\n    \"start\": 31,\n    \"end\": 37,\n    \"answer\": \"London\"\n  },\n  {\n    \"score\": 0.9326565265655518,\n    \"start\": 11,\n    \"end\": 16,\n    \"answer\": \"Clara\"\n  },\n  {\n    \"score\": 0.750623881816864,\n    \"start\": 201,\n    \"end\": 230,\n    \"answer\": \"Amazonia or the Amazon Jungle\"\n  }\n]\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1703408384695
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Let's make the output prettier and print it in below format:\n",
        "\n",
        "\"Context: \" \n",
        "\n",
        "\"Question: \" \n",
        "\n",
        "\"Answer: \""
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(input_question)):\n",
        "    print(\"Context: \" + input_context[i])\n",
        "    print(\"Question: \" + input_question[i])\n",
        "    print(\"Answer: \" + response_json[i][\"answer\"])\n",
        "    print(\"\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Context: My name is Wolfgang and I live in Berlin\nQuestion: Where do I live?\nAnswer: Berlin\n\n\nContext: My name is Sarah and I live in London\nQuestion: Where do I live?\nAnswer: London\n\n\nContext: My name is Clara and I live in Berkeley.\nQuestion: What's my name?\nAnswer: Clara\n\n\nContext: The Amazon rainforest (Portuguese: Floresta Amazônica or Amazônia; Spanish: Selva Amazónica, Amazonía or usually Amazonia; French: Forêt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \"Amazonas\" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.\nQuestion: Which name is also used to describe the Amazon rainforest in English?\nAnswer: Amazonia or the Amazon Jungle\n\n\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1703408384907
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Delete the online endpoint\n",
        "Don't forget to delete the online endpoint, else you will leave the billing meter running for the compute used by the endpoint."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# workspace_ml_client.online_deployments.begin_delete(demo_deployment)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'score': 0.2117144614458084, 'start': 59, 'end': 84, 'answer': 'gives freedom to the user'}\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1703396670873
        },
        "editable": true,
        "run_control": {
          "frozen": false
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}